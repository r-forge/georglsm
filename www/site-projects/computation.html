<!DOCTYPE HTML PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type"
 content="text/html; charset=ISO-8859-1">
  <meta name="description" content="Website short description.">
  <meta name="keywords" content="website main keywords">
  <title>Simple Websites</title>
  <link href="style.css" rel="stylesheet" type="text/css">
</head>
<body>
<div id="container">
<div id="header">
<h1>Data Mining, Statistical Modeling and Computing<br>
</h1>
</div>
<div id="sub_header">... a few things done by Liang</div>
<div id="main_content_top"></div>
<div id="main_content">
<div class="content">
<h2>Computation</h2>
<p class="quote">Lately, I've been working to convince myself that
everything is a computation.</p>
<p style="text-align: right;" class="quote">-Rudy Rucker<br>
</p>
<p>Here listed a few techical reports and manuscripts&nbsp; related to
statistical computing.<br>
<br>
</p>
<ul>
  <li>
    <h3>geoCount: a R Package of Bayesian Estimation and Model Checking
for Generalized Linear Spatial Models<br>
    </h3>
  </li>
</ul>
<div style="text-align: right;">Manuscript [<a>under writting</a>]</div>
<span style="font-weight: bold;">Keywords: </span>hierarchical models,
robust MCMC, latent variables, parallel computing, R/C++ API, Bayesian
model checking, transformed residuals<br>
<span style="font-weight: bold;">Abstract: </span>Model fitting and
checking has remained difficult for hierarchical models with complex
structure, such as generalized linear spatial models. Because of
multi-layer hierarchy and the large number of unobserved latent
variables, posterior sampling for latent variables and hyper-parameters
usually cannot achieve good convergence. In this package, we applied
up-to-date robust MCMC algorithms which not only provide fast mixing
and quick convergence of the chains but also small correlation between
posterior samples of different variables or parameters. Furthmore, we
speed up the generation of Markov chains with parallel computing
techniques. Also, Bayesian model checking methods and a new method
based on transformed residuals are implemented ...<br>
<br>
<ul>
  <li>
    <h3>Communications between R and C++<br>
    </h3>
  </li>
</ul>
<div style="text-align: right;">Report [<a>pdf</a>]<br>
Code
[Rcpp.R] [Rinside.cpp] [module.cpp]</div>
<span style="font-weight: bold;">Keywords: </span>incoming ...<br>
<span style="font-weight: bold;">Abstract: </span>incoming ...<br>
<br>
<ul>
  <li>
    <h3>Parallel Computing with R and How to Use it on High Performance
Computing Clusters<br>
    </h3>
  </li>
</ul>
<div style="text-align: right;">Report [<a href="pdf/paraCompR.pdf">pdf</a>]<br>
Code
[<a href="code/snow.R">snow.R</a>] [<a href="code/snow_cv.R">snow_CV.R</a>]
[<a href="code/snow_bootstrap.R">snow_BS.R</a>]<br>
[<a href="code/snowfall_example.R">snowfall.R</a>] [<a
 href="code/multicore.R">multicore.R</a>] [<a href="code/parallel.job">parallel.job</a>]
[<a href="code/array.job">array.job</a>]<br>
</div>
<span style="font-weight: bold;">Keywords: </span>Rmpi, snow,
snowfall, multicore, wrapper function, HPC, job script<br>
<span style="font-weight: bold;">Abstract: </span>Methodological
advances have led to much more computationally demand in statistical
computing, such as Markov chain Monte Carlo (MCMC) algorithms,
bootstrapping, cross-validation, Monte Carlo simulation, etc. And many
areas of statistical applications are experiencing rapid growth in the
size of data sets. Parallel computing is a common approach to resolve
these problems. In this paper, four most promising packages for
parallel computing with R are introduced with examples of
implementation. And the procedure about how to use R in parallel way on
high performance computing cluster is illustrated.<br>
<br>
<ul>
  <li>
    <h3>Improved Robust MCMC Algorithm for Hierarchical Models<br>
    </h3>
  </li>
</ul>
<div style="text-align: right;">Report [<a href="pdf/Robust_MCMC.pdf">pdf</a>]</div>
<span style="font-weight: bold;">Keywords: </span>Hastings-within-Gibbs,
slow
mixing,
group
updating, Langevin algorithm, data-corrected
parameterization,
flat prior<br>
<span style="font-weight: bold;">Abstract: </span>In this paper, three
important techniques are discussed with details: group updating
scheme, Langevin algorithm, data-corrected parameterization. They
largely improve the performance of Hastings-within-Gibbs algorithm. And
these improvements are illustrated through application on a
hierarchical model with Rongelap data.<br>
<br>
<ul>
  <li>
    <h3>Hastings-within-Gibbs Algorithm: Introduction and Application
on Hierarchical Models<br>
    </h3>
  </li>
</ul>
<div style="text-align: right;">Report [<a
 href="pdf/Hastings_within_Gibbs.pdf">pdf</a>]</div>
<span style="font-weight: bold;">Keywords: </span>MCMC, Gibbs sampler,
Metropolis-Hastings, "fix-scan", slow mixing<br>
<span style="font-weight: bold;">Abstract: </span>In this paper,
common MCMC algorithms are introduced including Hastings-within-Gibbs
algorithm. Then it is applied to a hierarchical model with simulated
data set. &#8220;Fix-scan&#8221; technique is used to update the latent variables
in the model. And the results are studied to explore the problems of
the algorithm.<br>
<br>
<p>
</p>
<ul>
  <li>
    <h3>Nested Sampling: Introduction and Implementation<br>
    </h3>
  </li>
</ul>
<div style="text-align: right;">Report [<a href="pdf/7113_2.pdf">pdf</a>]<br>
Code
[<a href="code/nested_norm.R">nested_norm.R</a>] [<a
 href="code/nested_exp.R">nested_exp.R</a>]
[<a href="code/nested_growth.R">nested_growth.R</a>]</div>
<span style="font-weight: bold;">Keywords: </span>marginal density of
the data, Monte Carlo methods, cumulative prior mass, parameter space,
shrinkage of the likelihood, terminnation condition, wrap-around and
reflection technique<br>
<span style="font-weight: bold;">Abstract: </span>Nested Sampling is a
new technique to calculate the evidence, (alternatively the marginal
likelihood, marginal density of the data, or the prior predictive), in
a way that uses Monte Carlo methods ...<br>
<br>
<ul>
  <li>
    <h3>MCMC Algorithms for LMMs and GLMMs: Implementation in R and
Comparison with WinBUGS<br>
    </h3>
  </li>
</ul>
<div style="text-align: right;">Report [<a href="pdf/7113_1.pdf">pdf</a>]<br>
Code
[<a href="code/7113_caseI.R">caseI.R</a>] [<a href="code/7113_caseII.R">caseII.R</a>]
[<a href="code/7113_caseIII.R">caseIII.R</a>]
[<a href="code/7113_caseI_compare.R">caseI_c.R</a>]
</div>
<span style="font-weight: bold;">Keywords: </span>mixed models,
Bayesian analysis, hierarchical structure, Gibbs sampler,
Metropolis-Hastings algorithm<br>
<span style="font-weight: bold;">Abstract: </span>Although we already
have WinBUGS for posterior sampling, all the computation in WinBUGS
runs in a "black-box" and it is almost impossible to control or modify
the internal algorithms for specific needs. One the other hand,
generalized linear mixed models (GLMMs) are getting popular because of
its capability to handle an extraordinary range of complications in
regression analysis ...<br>
<p><br>
Contact ljing918@gmail.com if there is any question.</p>
</div>
<div class="menu">
<div class="menu_title">&nbsp;Menu</div>
<ul>
  <li><a href="index.html" class="menu_link">Home</a></li>
  <li><a href="modeling.html" class="menu_link">Modeling</a></li>
  <li><a href="computation.html" class="menu_link">Computation</a></li>
  <li><a href="http://georglsm.r-forge.r-project.org/" class="menu_link">R
Package
Dev<br>
    </a></li>
  <li><a href="#" class="menu_link">Code</a></li>
  <li><a href="pdf/resume_ljing.pdf" class="menu_link">About Me<br>
    </a></li>
</ul>
</div>
<div id="clear"></div>
</div>
<div id="main_content_bottom">
</div>
<div id="footer"><strong>Copyright &copy; 2011</strong> | <a href="#">Liang's
Site</a> | <b>Design by</b> <a href="http://gendesigns.blogspotcom">Gen</a></div>
</div>
</body>
</html>
